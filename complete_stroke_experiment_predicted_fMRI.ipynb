{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7c5ffd",
   "metadata": {},
   "source": [
    "# The complete stroke experiment on ROIs, Notebook version\n",
    "I just moved Jonathan's python file into a notebook file for easier debugging. Can delete it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c23e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roman's imports\n",
    "\n",
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import sys\n",
    "sys.path.append('/home/jonathak/VisualEncoder/DIP_decoder/GP-DIP/')\n",
    "import numpy as np\n",
    "from models import *\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from utils.denoising_utils import *\n",
    "import _pickle as cPickle\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sys.path.append('/home/romanb/PycharmProjects/BrainVisualReconst/')\n",
    "    \n",
    "# My imports and parameters\n",
    "\n",
    "sys.path.append('/home/jonathak/VisualEncoder/Analysis/Brain_maps')\n",
    "from NIPS_utils import get_hemisphere_indices, get_roi_indices\n",
    "\n",
    "sys.path.append('/home/jonathak/VisualEncoder/Voxels_Prediction')\n",
    "from predict_voxels_jonathan import get_images_for_prediction\n",
    "\n",
    "device = torch.device('cuda')\n",
    "from create_stroke_fMRI import StrokeVoxelPredictor\n",
    "stroke_predictor = StrokeVoxelPredictor()\n",
    "\n",
    "# This is Matanya's config file - just to play with the script\n",
    "from matanya_funcs import format_duration\n",
    "from datetime import timedelta\n",
    "import yaml \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff56403",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/matanyaw/DIP_decoder/matanyas_config.yaml', 'r') as f:\n",
    "    matanyas_config = yaml.safe_load(f)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "voxel_paths_blur_fill_excluded = {\n",
    "    'original_voxels_path': '/home/jonathak/VisualEncoder/Results/all_masks_coarse_blur_excluded_sub_1/original_voxels.pt',\n",
    "}\n",
    "voxel_paths_blur_fill_shared = {\n",
    "    'original_voxels_path': '/home/jonathak/VisualEncoder/Results/all_masks_coarse_blur_shared/original_voxels.pt',\n",
    "}\n",
    "voxel_paths = voxel_paths_blur_fill_shared \n",
    "\n",
    "\n",
    "# Loading models\n",
    "\n",
    "encoder = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_reg') # The Dinov2 encoder\n",
    "model = torch.load('/home/jonathak/VisualEncoder/Voxels_Prediction/model_ch128.pth').eval().cuda() # The universal encoder model\n",
    "\n",
    "# Defining subject\n",
    "stroke_sub = 1\n",
    "\n",
    "# Getting images\n",
    "\n",
    "# images = get_images_for_prediction(image_type='excluded', subjects=[stroke_sub])\n",
    "# images = get_images_for_prediction(image_type='shared', subjects=[stroke_sub])\n",
    "images = get_images_for_prediction(image_type=matanyas_config['image_type'], subjects=[stroke_sub])\n",
    "\n",
    "images = images.permute(0, 2, 3, 1)\n",
    "\n",
    "# Getting original predicted fMRI\n",
    "\n",
    "original_predicted_fMRI = torch.load(voxel_paths['original_voxels_path']).cuda()\n",
    "\n",
    "# Getting voxel indices\n",
    "\n",
    "lh_start, lh_end = get_hemisphere_indices(stroke_sub, 'lh')\n",
    "rh_start, rh_end = get_hemisphere_indices(stroke_sub, 'rh')\n",
    "inds = np.arange(lh_start, rh_end)\n",
    "\n",
    "NC = np.load(\"/home/romanb/data/datasets/NVD/tutorial_data/noise_ceiling/noise_ceiling.npy\")\n",
    "\n",
    "inds_nc = np.where(NC[inds]>0.5)[0]\n",
    "inds_nc_torch = torch.from_numpy(inds_nc)\n",
    "\n",
    "# Image processing functions\n",
    "\n",
    "mean = torch.tensor((0.485, 0.456, 0.406)).reshape(1,3,1,1).cuda()\n",
    "std = torch.tensor((0.229, 0.224, 0.225)).reshape(1,3,1,1).cuda()\n",
    "\n",
    "def trans_imgs(imgs):\n",
    "    imgs = imgs/255.0\n",
    "    imgs =  imgs.permute(2,0,1).float()\n",
    "    return imgs\n",
    "\n",
    "def save_as_png(array, save_path):\n",
    "    \n",
    "    # If the image is a troch tensor, convert it to a numpy array\n",
    "    if isinstance(array, torch.Tensor):\n",
    "        array = array.cpu().numpy()\n",
    "    \n",
    "    # If array is (3,224,224), transpose it\n",
    "    if array.shape[0] == 3:\n",
    "        array = array.transpose(1, 2, 0)\n",
    "    \n",
    "    # Check if values are floats between 0-1 and scale accordingly\n",
    "    if array.dtype == np.float32 or array.dtype == np.float64:\n",
    "        array = (array * 255).astype(np.uint8)\n",
    "    elif array.dtype == np.uint8:\n",
    "        # Already in correct range, no scaling needed\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported array dtype: {array.dtype}. Expected float32/64 or uint8\")\n",
    "    \n",
    "    # Save as PNG\n",
    "    plt.imsave(save_path, array)\n",
    "    \n",
    "# DIP parameters\n",
    "\n",
    "INPUT = 'noise'\n",
    "pad = 'reflection'\n",
    "OPT_OVER = 'net' # optimize over the net parameters only\n",
    "c = 1./30.\n",
    "reg_noise_std = 1./30.\n",
    "\n",
    "learning_rate = LR = 0.001\n",
    "exp_weight=0.99\n",
    "input_depth = 32 \n",
    "roll_back = True # to prevent numerical issues\n",
    "num_iter_no_stroke = 4001 # 3201 max iterations\n",
    "num_iter_stroke = 601 # 3201 max iterations\n",
    "burnin_iter = 7000 # burn-in iteration for SGLD\n",
    "weight_decay = 5e-8\n",
    "mse = torch.nn.MSELoss().type(dtype) # loss\n",
    "\n",
    "save_throughout = True\n",
    "n_saves = 5\n",
    "save_every = num_iter_stroke // n_saves\n",
    "\n",
    "# Defining the desired ROI masks\n",
    "\n",
    "ROIs_bodies = ['EBA', 'FBA-1', 'FBA-2', 'mTL-bodies']\n",
    "ROIs_faces = ['OFA', 'FFA-1', 'FFA-2', 'mTL-faces', 'aTL-faces']\n",
    "ROIs_places = ['OPA', 'PPA', 'RSC']\n",
    "ROIs_words = ['OWFA', 'VWFA-1', 'VWFA-2', 'mfs-words', 'mTL-words']\n",
    "\n",
    "ROIs = ROIs_bodies + ROIs_faces + ROIs_places + ROIs_words\n",
    "\n",
    "# Creating image indices\n",
    "\n",
    "# images_indices = np.sort(np.array([1, 5, 6, 9, 12, 13, 14, 22, 28, 27, 66, 119, 39, 109, 56, 44, 69]))\n",
    "# images_indices = [69,109,119]\n",
    "\n",
    "# images_indices = np.sort(np.array([1, 5, 6, 9, 12, 13, 14, 22, 28, 27, 66, 69, 39, 109, 56, 44])) # For excluded\n",
    "# images_indices = np.sort(np.array([1, 4, 7, 9, 15, 16, 18, 20, 21, 29, 51, 65, 69, 96, 99])) # For shared\n",
    "\n",
    "images_indices = np.sort(np.array(matanyas_config['images_indices']))\n",
    "\n",
    "\n",
    "# Results path\n",
    "\n",
    "root_save_path = matanyas_config['root_save_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The images loop\n",
    "\n",
    "for image_counter, img_idx in enumerate(images_indices, start=1):\n",
    "    \n",
    "    if image_counter > 1:\n",
    "        t = time.time()\n",
    "        print(f'Image {image_counter-1} out of {len(images_indices)} finished in {timedelta(seconds=t - start_time)}')\n",
    "    \n",
    "    save_path = f'{root_save_path}/img_{img_idx}'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Saving the original image\n",
    "    save_as_png(images[img_idx], f'{save_path}/img_{img_idx}_original_image.png')\n",
    "    \n",
    "    # Getting the stroke fill value\n",
    "    min_val = original_predicted_fMRI[img_idx,inds].min()\n",
    "    \n",
    "    # Original target voxel maps\n",
    "    original_target_all = original_predicted_fMRI[img_idx,inds].unsqueeze(0).float().to(device)\n",
    "    original_target_nc = original_predicted_fMRI[img_idx,inds_nc].unsqueeze(0).float().to(device)\n",
    "\n",
    "\n",
    "    # Step 1: Fitting the network to the image\n",
    "    # =====================================\n",
    "    if 1 not in matanyas_config['steps_to_do']:\n",
    "        continue\n",
    "\n",
    "    in_img = trans_imgs(images[img_idx])\n",
    "\n",
    "    # Initialize DIP network\n",
    "    net = get_net(input_depth, 'skip', pad,\n",
    "                skip_n33d=128, \n",
    "                skip_n33u=128,\n",
    "                skip_n11=2,\n",
    "                num_scales=3,\n",
    "                upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "    ## Optimize\n",
    "    net_input = get_noise(input_depth, INPUT, (224, 224),var=0.1).type(dtype).detach()\n",
    "    net_input_saved = net_input.detach().clone()\n",
    "    noise = net_input.detach().clone()\n",
    "    out_avg = None\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    out = net(net_input)\n",
    "    rec_img_np = out.detach().cpu().numpy()[0]\n",
    "\n",
    "    def closure():\n",
    "\n",
    "        global i, out_avg, net_input, out_avg_np\n",
    "        if reg_noise_std > 0:\n",
    "            net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        out = net(net_input)\n",
    "\n",
    "        if out_avg is None:\n",
    "            out_avg = out.detach()\n",
    "        else:\n",
    "            out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
    "\n",
    "        loss = F.mse_loss(out, in_img.cuda())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        out_avg_np = out_avg.detach().cpu().numpy()[0]\n",
    "        \n",
    "        # Saving intermediate image\n",
    "        # if save_throughout and i % save_every == 0 and i != 0:\n",
    "        #     save_as_png(out_avg_np, f'{save_path}/img_{img_idx}_fitted_image_iter_{i}.png')\n",
    "        \n",
    "        i += 1\n",
    "        return loss\n",
    "\n",
    "    ## Optimizing \n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "    for j in range(num_iter_no_stroke):\n",
    "        optimizer.zero_grad()\n",
    "        closure()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Finished fitting on image for image {img_idx}')\n",
    "    \n",
    "    # Saving the fitted image\n",
    "    save_as_png(out_avg_np, f'{save_path}/img_{img_idx}_fitted_image_final.png')\n",
    "    \n",
    "    # Saving the fitted network\n",
    "    torch.save({\n",
    "        'net_state': net.state_dict(),\n",
    "        'out_avg': out_avg\n",
    "    }, os.path.join(save_path, 'dip_on_original_image.pth'))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Step 2: Decoding normal fMRI voxel map\n",
    "    # ===================================\n",
    "    if 2 not in matanyas_config['steps_to_do']:\n",
    "        continue\n",
    "    net = get_net(input_depth, 'skip', pad,\n",
    "                    skip_n33d=128, \n",
    "                    skip_n33u=128,\n",
    "                    skip_n11=2,\n",
    "                    num_scales=3,\n",
    "                    upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "    checkpoint = torch.load(os.path.join(save_path, 'dip_on_original_image.pth'))\n",
    "    net.load_state_dict(checkpoint['net_state'])\n",
    "\n",
    "    out_avg = checkpoint['out_avg']\n",
    "\n",
    "    reg_noise_std = 1./30.\n",
    "    i = 0 \n",
    "\n",
    "    def closure():\n",
    "\n",
    "        global i, out_avg, net_input, out_avg_np\n",
    "        \n",
    "        if reg_noise_std > 0:\n",
    "            net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        out = net(net_input)\n",
    "\n",
    "        if out_avg is None:\n",
    "            out_avg = out.detach()\n",
    "        else:\n",
    "            out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
    "        \n",
    "        enc_in = (out-mean)/std\n",
    "        vox_pred = model(enc_in, inds_nc_torch.unsqueeze(0).cuda())\n",
    "        \n",
    "        loss = F.mse_loss(vox_pred, original_target_nc)     # How close we are to the original fMRI voxel map\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        out_avg_np = out_avg.detach().cpu().numpy()[0]\n",
    "        \n",
    "        # # Saving intermediate image\n",
    "        # if save_throughout and i % save_every == 0 and i != 0:\n",
    "        #     save_as_png(out_avg_np, f'{save_path}/img_{img_idx}_normal_fMRI_iter_{i}.png')\n",
    "\n",
    "        i += 1\n",
    "        return loss\n",
    "\n",
    "    ## Optimizing \n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "    for j in range(num_iter_no_stroke):\n",
    "        optimizer.zero_grad()\n",
    "        closure()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Finished decoding original fMRI for image {img_idx}')\n",
    "    \n",
    "    # MAYBE REMOVE- start from fMRI \n",
    "    torch.save({\n",
    "        'net_state': net.state_dict(),\n",
    "        'out_avg': out_avg\n",
    "    }, os.path.join(save_path, 'dip_on_fMRI_image.pth'))\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Saving the normal fMRI final image\n",
    "    save_as_png(out_avg_np, f'{save_path}/img_{img_idx}_normal_fMRI_final.png')\n",
    "    \n",
    "    # The ROI masks loop\n",
    "    # ==================\n",
    "    \n",
    "    for ROI in ROIs:\n",
    "        \n",
    "        stroke_indices = get_roi_indices(stroke_sub, ROI)\n",
    "        \n",
    "        # Check if the ROI exists for this subject\n",
    "        if stroke_indices is None:\n",
    "            continue\n",
    "        \n",
    "        stroke_target_all = original_target_all.clone().detach()\n",
    "        stroke_target_all[0, stroke_indices] = stroke_target_all.min()\n",
    "        stroke_target_all = stroke_target_all.float()\n",
    "        stroke_target_nc = stroke_target_all[:,inds_nc]\n",
    "\n",
    "        # Counting stroke voxels in the nc case\n",
    "        current_stroke_indices_count = torch.sum((original_target_nc != min_val) & (stroke_target_nc == min_val))\n",
    "\n",
    "        # Moving to cuda\n",
    "        stroke_target_all = stroke_target_all.to(device)\n",
    "        stroke_target_nc = stroke_target_nc.to(device)\n",
    "        \n",
    "        # Step 3.1: Decoding stroke fMRI voxel map\n",
    "        # ===================================\n",
    "\n",
    "        if 3 not in matanyas_config['steps_to_do']:\n",
    "            continue\n",
    "\n",
    "        net = get_net(input_depth, 'skip', pad,\n",
    "        skip_n33d=128, \n",
    "        skip_n33u=128,\n",
    "        skip_n11=2,\n",
    "        num_scales=3,\n",
    "        upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "        # Starting from original image\n",
    "        checkpoint = torch.load(os.path.join(save_path, 'dip_on_original_image.pth'))\n",
    "        net.load_state_dict(checkpoint['net_state'])\n",
    "        out_avg = checkpoint['out_avg']\n",
    "\n",
    "        reg_noise_std = 1./30.\n",
    "        i = 0 \n",
    "\n",
    "        def closure():\n",
    "\n",
    "            global i, out_avg, net_input, out_avg_np\n",
    "            \n",
    "            if reg_noise_std > 0:\n",
    "                net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "            out = net(net_input)\n",
    "\n",
    "            if out_avg is None:\n",
    "                out_avg = out.detach()\n",
    "            else:\n",
    "                out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
    "            \n",
    "            enc_in = (out-mean)/std\n",
    "            vox_pred = model(enc_in, inds_nc_torch.unsqueeze(0).cuda())\n",
    "            \n",
    "            loss = F.mse_loss(vox_pred, stroke_target_nc)#+total_variation_loss(out)+0.01*norm_6(out)#- 0.1*torch.mean(F.cosine_similarity(vox_pred, target))\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            out_avg_np = out_avg.detach().cpu().numpy()[0]\n",
    "\n",
    "            # Saving intermediate image \n",
    "            if save_throughout and i % save_every == 0 and i != 0:\n",
    "                save_as_png(out_avg_np, f'{save_path}/img_{img_idx}_stroke_{ROI}_iter_{i}_start_original.png')\n",
    "            i += 1\n",
    "            return loss\n",
    "\n",
    "        ## Optimizing \n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "        for j in range(num_iter_stroke):\n",
    "            optimizer.zero_grad()\n",
    "            closure()\n",
    "            optimizer.step()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Saving the stroke fMRI final image\n",
    "        save_as_png(out_avg_np, f'{save_path}/img_{img_idx}_stroke_{ROI}_start_original.png')\n",
    "        \n",
    "        # Step 3.2: Decoding stroke fMRI voxel map\n",
    "        # ===================================\n",
    "\n",
    "        if 4 not in matanyas_config['steps_to_do']:\n",
    "            continue\n",
    "\n",
    "        checkpoint = torch.load(os.path.join(save_path, 'dip_on_fMRI_image.pth'))\n",
    "        net.load_state_dict(checkpoint['net_state'])\n",
    "        out_avg = checkpoint['out_avg']\n",
    "\n",
    "        reg_noise_std = 1./30.\n",
    "        i = 0 \n",
    "\n",
    "        def closure():\n",
    "\n",
    "            global i, out_avg, net_input, out_avg_np\n",
    "            \n",
    "            if reg_noise_std > 0:\n",
    "                net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "            out = net(net_input)\n",
    "\n",
    "            if out_avg is None:\n",
    "                out_avg = out.detach()\n",
    "            else:\n",
    "                out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
    "            \n",
    "            enc_in = (out-mean)/std\n",
    "            vox_pred = model(enc_in, inds_nc_torch.unsqueeze(0).cuda())\n",
    "            \n",
    "            loss = F.mse_loss(vox_pred, stroke_target_nc)#+total_variation_loss(out)+0.01*norm_6(out)#- 0.1*torch.mean(F.cosine_similarity(vox_pred, target))\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            out_avg_np = out_avg.detach().cpu().numpy()[0]\n",
    "            \n",
    "            # Saving intermediate image \n",
    "            if save_throughout and i % save_every == 0 and i != 0:\n",
    "                save_as_png(out_avg_np, f'{save_path}/img_{img_idx}_stroke_{ROI}_iter_{i}_start_fMRI.png')\n",
    "            \n",
    "            i += 1\n",
    "            return loss\n",
    "\n",
    "        ## Optimizing \n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "        for j in range(num_iter_stroke):\n",
    "            optimizer.zero_grad()\n",
    "            closure()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f'Finished decoding stroke fMRI for image {img_idx}, {ROI}')\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "        # Saving the stroke fMRI final image\n",
    "        save_as_png(out_avg_np, f'{save_path}/img_{img_idx}_stroke_{ROI}_start_fMRI.png')    \n",
    "    \n",
    "\n",
    "\n",
    "print('Finished all experiments!')\n",
    "end_time = time.time()\n",
    "print(f'Total time taken: {timedelta(seconds=end_time - start_time)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
